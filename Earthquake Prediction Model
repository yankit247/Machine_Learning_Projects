## Earthquake Prediction Model **

# LINEAR REGRESSION MODEL ##
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Function to load and preprocess data
def load_and_preprocess_data(file_path):
    df = pd.read_csv(file_path, delimiter=r'\s+')
    df.columns = ["Date(YYYY/MM/DD)", "Time(UTC)", "Latitude(deg)", "Longitude(deg)", "Depth(km)",
                  "Magnitude(ergs)", "Magnitude_type", "No_of_Stations", "Gap", "Close", "RMS", "SRC", "EventID"]
    
    ts = pd.to_datetime(df["Date(YYYY/MM/DD)"] + " " + df["Time(UTC)"])
    df.index = ts
    df.drop(["Date(YYYY/MM/DD)", "Time(UTC)"], axis=1, inplace=True)
    
    return df

# Function to train a Linear Regression model
def train_linear_regression_model(X_train, y_train):
    model = LinearRegression()
    model.fit(X_train, y_train)
    return model

# Function to evaluate the model and print scores
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    print("R^2: {:.2f}, MSE: {:.2f}".format(r2, mse))

# Function to make predictions on new data
def predict_new_data(model, new_data):
    new_pred = model.predict(new_data)
    return new_pred

# Function to create visualization of regression lines
def visualize_regression_lines(X_test, y_test):
    sns.set(style="whitegrid")
    predictors = ['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'No_of_Stations']

    for predictor in predictors:
        plt.figure()
        sns.regplot(x=X_test[predictor], y=y_test, scatter_kws={'s': 10})
        plt.xlabel(predictor)
        plt.ylabel('Magnitude')
        plt.title('Multiple Linear Regression Model')
    
    plt.show()

def main():
    # Load and preprocess the data
    file_path = 'Earthquake_Data.csv'
    df = load_and_preprocess_data(file_path)
    print("Data loaded and preprocessed successfully.")

    # Select relevant columns
    X = df[['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'No_of_Stations']]
    y = df['Magnitude(ergs)']

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # Train the linear regression model
    model = train_linear_regression_model(X_train, y_train)
    print("Linear regression model trained successfully.")

    # Evaluate the model
    evaluate_model(model, X_test, y_test)

    # Define new data points
    new_data = [[33.89, -118.40, 16.17, 11], [37.77, -122.42, 8.05, 14]]

    # Predict using the trained model
    new_pred = predict_new_data(model, new_data)
    print("New predictions:", new_pred)

    # Visualize regression lines
    visualize_regression_lines(X_test, y_test)

if __name__ == "__main__":
    main()


## RANDOM FOREST MODEL

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error

# Function to load and preprocess data
def load_and_preprocess_data(file_path):
    df = pd.read_csv(file_path, delimiter=r'\s+')
    df.columns = ["Date(YYYY/MM/DD)", "Time(UTC)", "Latitude(deg)", "Longitude(deg)", "Depth(km)",
                  "Magnitude(ergs)", "Magnitude_type", "No_of_Stations", "Gap", "Close", "RMS", "SRC", "EventID"]
    
    ts = pd.to_datetime(df["Date(YYYY/MM/DD)"] + " " + df["Time(UTC)"])
    df.index = ts
    df.drop(["Date(YYYY/MM/DD)", "Time(UTC)"], axis=1, inplace=True)
    
    return df

# Function to train a Random Forest model
def train_random_forest_model(X_train, y_train):
    model = RandomForestRegressor(n_estimators=100, random_state=0)
    model.fit(X_train, y_train)
    return model

# Function to evaluate the model and print scores
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    print("R^2: {:.2f}, MSE: {:.2f}".format(r2, mse))

# Function to make predictions on new data
def predict_new_data(model, new_data):
    new_pred = model.predict(new_data)
    return new_pred

# Function to create visualization of feature importance
def visualize_feature_importance(model, X_train):
    feature_importance = model.feature_importances_
    predictors = ['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'No_of_Stations']
    
    plt.figure()
    sns.barplot(x=predictors, y=feature_importance)
    plt.xlabel('Predictor Variables')
    plt.ylabel('Feature Importance')
    plt.title('Random Forest Feature Importance')
    plt.show()

def main():
    # Load and preprocess the data
    file_path = 'Earthquake_Data.csv'
    df = load_and_preprocess_data(file_path)
    print("Data loaded and preprocessed successfully.")

    # Select relevant columns
    X = df[['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'No_of_Stations']]
    y = df['Magnitude(ergs)']

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # Train the Random Forest model
    model = train_random_forest_model(X_train, y_train)
    print("Random Forest model trained successfully.")

    # Evaluate the model
    evaluate_model(model, X_test, y_test)

    # Define new data points
    new_data = [[33.89, -118.40, 16.17, 11], [37.77, -122.42, 8.05, 14]]

    # Predict using the trained model
    new_pred = predict_new_data(model, new_data)
    print("New predictions:", new_pred)

    # Visualize feature importance
    visualize_feature_importance(model, X_train)

if __name__ == "__main__":
    main()


## SUPPORT VECTOR MACHINE ## 


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error

# Function to load and preprocess data
def load_and_preprocess_data(file_path):
    df = pd.read_csv(file_path, delimiter=r'\s+')
    df.columns = ["Date(YYYY/MM/DD)", "Time(UTC)", "Latitude(deg)", "Longitude(deg)", "Depth(km)",
                  "Magnitude(ergs)", "Magnitude_type", "No_of_Stations", "Gap", "Close", "RMS", "SRC", "EventID"]
    
    ts = pd.to_datetime(df["Date(YYYY/MM/DD)"] + " " + df["Time(UTC)"])
    df.index = ts
    df.drop(["Date(YYYY/MM/DD)", "Time(UTC)"], axis=1, inplace=True)
    
    return df

# Function to train an SVM regression model
def train_svm_model(X_train, y_train):
    model = SVR(kernel='linear')
    model.fit(X_train, y_train)
    return model

# Function to evaluate the model and print scores
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    print("R^2: {:.2f}, MSE: {:.2f}".format(r2, mse))

# Function to make predictions on new data
def predict_new_data(model, new_data):
    new_pred = model.predict(new_data)
    return new_pred

def main():
    # Load and preprocess the data
    file_path = 'Earthquake_Data.csv'
    df = load_and_preprocess_data(file_path)
    print("Data loaded and preprocessed successfully.")

    # Select relevant columns
    X = df[['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'No_of_Stations']]
    y = df['Magnitude(ergs)']

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # Train the SVM regression model
    model = train_svm_model(X_train, y_train)
    print("SVM model trained successfully.")

    # Evaluate the model
    evaluate_model(model, X_test, y_test)

    # Define new data points
    new_data = [[33.89, -118.40, 16.17, 11], [37.77, -122.42, 8.05, 14]]

    # Predict using the trained model
    new_pred = predict_new_data(model, new_data)
    print("New predictions:", new_pred)

if __name__ == "__main__":
    main()


